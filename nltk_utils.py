import nltk 
#nltk.download('punkt') #pre-trained tokenizer
def tokenize(text):
    return nltk.word_tokenize(text)

def stem(word):
    pass

def bag_of_words(tokenized_sentence, all_words):
    pass 